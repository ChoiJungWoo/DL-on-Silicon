

---------

        It’s likely that, within the next two to three years, the AI industry will converge around one open-source cross-compilation supported by all front-end and back-end environments. Other industry developments in recent weeks call attention to the opening of the AI cross-compilation ecosystem.

        These include:

        - Microsoft’s open-sourcing of a GitHub repo to foster cross-framework benchmarking of GPU-optimized deep learning models.
        - ARM’s partnership with Nvidia to integrate the open-source Nvidia Deep Learning Accelerator architecture into its just-announced Project Trillium platform, designed to enable cross-framework deep learning model compilation for optimized execution in mobile, “internet of things” and other mass-market edge devices.
        - IBM’s launch of the new open-source Fabric for Deep Learning framework, which supports optimized deployment of deep-learning microservices built in TensorFlow, PyTorch, Caffe2 and other frameworks to diverse compute nodes on heterogeneous clusters of GPUs and CPUs via stateless RESTful interfaces over Kubernetes.
        - Linux Foundation’s launch of the Acumos AI Project, which defines APIs, an open-source framework, and an AI model catalog for framework-agnostic AI app development, chaining and deployment over Kubernetes.


 More details on [DL compilers](https://github.com/gopala-kr/a-week-in-wild-ai/tree/master/12-ai-hardware-compilers)


      The aim of this project is to do the fundamental research and experimentation on
         - Existing/emerging ML/DL compiler optimization technologies 
         - Different hardwares/computing platforms which can accelerate ML/DL model training and inference(active research area)
         - Research on each computing platform and code optimization/synthesis from high level to low level machine code(active research area)
         - To find out how the existing platforms differ from each other and their offerings
         - To bring out the best in all frameworks, which helps in creating single open platform/standard.
         - To initiate a single cross-compilation open platform which simplifies integration of future frontend and backend environments.
         - To publish a papers on this research
         
------------------
----------------------

LLVM

- currently supports X86, X86-64, PowerPC, PowerPC-64, ARM, Thumb, SPARC, Alpha, CellSPU, MIPS, MSP430, SystemZ, and XCore.
- A Just-In-Time (JIT) code generation system, which currently supports X86, X86-64, ARM, AArch64, Mips, SystemZ, PowerPC, and PowerPC-64.


Halide

- CPU architectures: X86, ARM, MIPS, Hexagon, PowerPC
- Operating systems: Linux, Windows, Mac OS X, Android, iOS, Qualcomm QuRT
- GPU Compute APIs: CUDA, OpenCL, OpenGL, OpenGL Compute Shaders, Apple Metal, Microsoft Direct X 12



[Intel mpi-library](https://software.intel.com/en-us/mpi-library)


[opencl devices](https://www.khronos.org/conformance/adopters/conformant-products/opencl)


[OpenCL on Mobile Devices](http://arrayfire.com/opencl-on-mobile-devices/)

[OpenCL Resources](https://www.khronos.org/opencl/resources)

[CUDA GPUs](https://www.geforce.com/hardware/technology/cuda/supported-gpus)

--------------------
